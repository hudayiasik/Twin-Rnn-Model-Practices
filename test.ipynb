{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies.\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torchdata\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# hyper-parameters. (affect GPU memory size)\n",
    "_DiffEmbedDim_  = 128       # 128\n",
    "_DiffMaxLen_    = 600       # 200(0.7), 314(0.8), 609(0.9), 1100(0.95), 2200(0.98), 3289(0.99), 5000(0.995), 10000(0.9997)\n",
    "_DRnnHidSiz_    = 16        # 16\n",
    "_MsgEmbedDim_   = 128       # 128\n",
    "_MsgMaxLen_     = 200       # 54(0.9), 78(0.95), 130(0.98), 187(0.99), 268(0.995), 356(0.998), 516(0.999), 1434(1)\n",
    "_MRnnHidSiz_    = 32        # 16\n",
    "_TwinEmbedDim_  = 128       # 128\n",
    "_TwinMaxLen_    = 800       # 224(0.8), 425(0.9), 755(0.95), 1448(0.98), 2270(0.99)\n",
    "_TRnnHidSiz_    = 32        # 16\n",
    "# hyper-parameters. (affect training speed)\n",
    "_DRnnBatchSz_   = 128       # 128\n",
    "_DRnnLearnRt_   = 0.0001    # 0.0001\n",
    "_MRnnBatchSz_   = 128       # 128\n",
    "_MRnnLearnRt_   = 0.0001    # 0.0001\n",
    "_PRnnBatchSz_   = 256       # 256\n",
    "_PRnnLearnRt_   = 0.0005    # 0.0005\n",
    "_TRnnBatchSz_   = 256       # 256\n",
    "_TRnnLearnRt_   = 0.0005    # 0.0005\n",
    "# hyper-parameters. (trivial network parameters, unnecessary to modify)\n",
    "_DiffExtraDim_  = 2         # 2\n",
    "_TwinExtraDim_  = 1         # 1\n",
    "_DRnnHidLay_    = 1         # 1\n",
    "_MRnnHidLay_    = 1         # 1\n",
    "_TRnnHidLay_    = 1         # 1\n",
    "# hyper-parameters. (epoch related parameters, unnecessary to modify)\n",
    "_DRnnMaxEpoch_  = 1000      # 1000\n",
    "_DRnnPerEpoch_  = 1         # 1\n",
    "_DRnnJudEpoch_  = 10        # 10\n",
    "_MRnnMaxEpoch_  = 1000      # 1000\n",
    "_MRnnPerEpoch_  = 1         # 1\n",
    "_MRnnJudEpoch_  = 10        # 10\n",
    "_PRnnMaxEpoch_  = 1000      # 1000\n",
    "_PRnnPerEpoch_  = 1         # 1\n",
    "_PRnnJudEpoch_  = 10        # 10\n",
    "_TRnnMaxEpoch_  = 1000      # 1000\n",
    "_TRnnPerEpoch_  = 1         # 1\n",
    "_TRnnJudEpoch_  = 10        # 10\n",
    "# hyper-parameters. (flow control)\n",
    "_DEBUG_ = 0 #  0 : release\n",
    "            #  1 : debug\n",
    "_LOCK_  = 0 #  0 : unlocked - create random split sets.\n",
    "            #  1 : locked   - use the saved split sets.\n",
    "_MODEL_ = 0 #  0 : unlocked - train a new model.\n",
    "            #  1 : locked   - load the saved model.\n",
    "_DTYP_  = 1 #  0 : maintain both diff code and context code.\n",
    "            #  1 : only maintain diff code.\n",
    "_CTYP_  = 0 #  0 : maintain both the code and comments.\n",
    "            #  1 : only maintain code and delete comments.\n",
    "_NIND_ =  1 # -1 : not abstract tokens. (and will disable _NLIT_)\n",
    "            #  0 : abstract identifiers with VAR/FUNC.\n",
    "            #  1 : abstract identifiers with VARn/FUNCn.\n",
    "_NLIT_  = 1 #  0 : abstract literals with LITERAL.\n",
    "            #  1 : abstract literals with LITERAL/n.\n",
    "_TWIN_  = 1 #  0 : only twin neural network.\n",
    "            #  1 : twins + msg neural network.\n",
    "\n",
    "# print setting.\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "# Read the modified file\n",
    "df = pd.read_csv(\"./combined_codes_updated.csv\")\n",
    "\n",
    "# Extract the \"smellKey\" column values\n",
    "smellKey = df['SmellKey'].values\n",
    "\n",
    "# Print the contents of smell key list\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load the contents of function_smell_embeddings.pt\n",
    "old_embeddings = torch.load('./old_embeddings.pt')\n",
    "fixed_embeddings = torch.load('./fixdd _embeddings.pt')\n",
    "\n",
    "# Print the embeddings\n",
    "fixed_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list(['\\n']),\n",
       "        list([['     while(*s && d < e) {\\n', \"         if(unlikely(*s == '%')) {\\n\", '             if(likely(s[1] && s[2])) {\\n', '-                *d++ = from_hex(s[1]) << 4 | from_hex(s[2]);\\n', '+                char t = from_hex(s[1]) << 4 | from_hex(s[2]);\\n', '+                // avoid HTTP header injection\\n', \"+                *d++ = (char)((isprint(t))? t : ' ');\\n\", '                 s += 2;\\n', '             }\\n', '         }\\n'], ['     return web_client_api_request_single_chart(host, w, url, rrd_stats_api_v1_chart);\\n', ' }\\n', ' \\n', '+void fix_google_param(char *s) {\\n', '+    if(unlikely(!s)) return;\\n', '+\\n', '+    for( ; *s ;s++) {\\n', \"+        if(!isalnum(*s) && *s != '.' && *s != '_' && *s != '-')\\n\", \"+            *s = '_';\\n\", '+    }\\n', '+}\\n', '+\\n', ' // returns the HTTP code\\n', ' inline int web_client_api_request_v1_data(RRDHOST *host, struct web_client *w, char *url) {\\n', '     debug(D_WEB_CLIENT, \"%llu: API v1 data with URL \\'%s\\'\", w->id, url);\\n'], ['         }\\n', '     }\\n', ' \\n', '+    // validate the google parameters given\\n', '+    fix_google_param(google_out);\\n', '+    fix_google_param(google_sig);\\n', '+    fix_google_param(google_reqId);\\n', '+    fix_google_param(google_version);\\n', '+    fix_google_param(responseHandler);\\n', '+    fix_google_param(outFileName);\\n', '+\\n', '     if(!chart || !*chart) {\\n', '         buffer_sprintf(w->response.data, \"No chart id is given at the request.\");\\n', '         goto cleanup;\\n']]),\n",
       "        1],\n",
       "       [list(['\\n', 'While the client would bounds check the overall update\\n', 'region, it failed to bounds check the payload data\\n', 'parameters.\\n', '\\n', 'Add a test case to validate bounds checking.\\n', '\\n', 'https://bugzilla.gnome.org/show_bug.cgi?id=778048\\n', '\\n', 'CVE-2017-5884\\n', '\\n', 'Signed-off-by: Daniel P. Berrange <berrange@redhat.com>\\n']),\n",
       "        list([[' prev_version_file = /dev/null\\n', ' \\n', ' \\n', '-exclude_file_name_regexp--sc_bindtextdomain = ^examples/\\n', '+exclude_file_name_regexp--sc_bindtextdomain = ^examples/|src/.*test.c\\n', ' \\n', ' exclude_file_name_regexp--sc_preprocessor_indentation = ^*/*.[ch]\\n', ' \\n'], [' \\n', ' EXTRA_DIST = libgvnc_sym.version libgvncpulse_sym.version libgtk-vnc_sym.version vncmarshal.txt\\n', ' \\n', '+TESTS = vncconnectiontest\\n', '+\\n', '+noinst_PROGRAMS = $(TESTS)\\n', '+\\n', ' lib_LTLIBRARIES = libgvnc-1.0.la\\n', ' \\n', ' BUILT_SOURCES =\\n'], [' \\n', ' CLEANFILES = $(MARSHAL_FILES) $(ENUM_FILES)\\n', ' \\n', '+vncconnectiontest_SOURCES = vncconnectiontest.c\\n', '+vncconnectiontest_CFLAGS = $(GOBJECT_CFLAGS)\\n', '+vncconnectiontest_LDADD = libgvnc-1.0.la\\n', '+\\n', ' if WITH_PYTHON\\n', ' pyexec_LTLIBRARIES = gtkvnc.la\\n', ' \\n'], ['     (vnc_connection_tight_sum_pixel_func *)vnc_connection_tight_sum_pixel_32x32,\\n', ' };\\n', ' \\n', '+static gboolean vnc_connection_validate_boundary(VncConnection *conn,\\n', '+                                                 guint16 x, guint16 y,\\n', '+                                                 guint16 width, guint16 height)\\n', '+{\\n', '+    VncConnectionPrivate *priv = conn->priv;\\n', '+\\n', '+    if ((x + width) > priv->width || (y + height) > priv->height) {\\n', '+        vnc_connection_set_error(conn, \"Framebuffer update %dx%d at %d,%d \"\\n', '+                                 \"outside boundary %dx%d\",\\n', '+                                 width, height, x, y, priv->width, priv->height);\\n', '+    }\\n', '+\\n', '+    return !vnc_connection_has_error(conn);\\n', '+}\\n', '+\\n', ' \\n', ' static void vnc_connection_raw_update(VncConnection *conn,\\n', '                                       guint16 x, guint16 y,\\n'], ['     src_x = vnc_connection_read_u16(conn);\\n', '     src_y = vnc_connection_read_u16(conn);\\n', ' \\n', '+    if (!vnc_connection_validate_boundary(conn, src_x, src_y, width, height))\\n', '+        return;\\n', '+\\n', '     vnc_framebuffer_copyrect(priv->fb,\\n', '                              src_x, src_y,\\n', '                              dst_x, dst_y,\\n'], ['                 xy = vnc_connection_read_u8(conn);\\n', '                 wh = vnc_connection_read_u8(conn);\\n', ' \\n', '+                if (!vnc_connection_validate_boundary(conn, x + nibhi(xy), y + niblo(xy),\\n', '+                                                      nibhi(wh) + 1, niblo(wh) + 1))\\n', '+                    return;\\n', '+\\n', '                 vnc_framebuffer_fill(priv->fb, fg,\\n', '                                      x + nibhi(xy), y + niblo(xy),\\n', '                                      nibhi(wh) + 1, niblo(wh) + 1);\\n'], ['         sub_w = vnc_connection_read_u16(conn);\\n', '         sub_h = vnc_connection_read_u16(conn);\\n', ' \\n', '+        if (!vnc_connection_validate_boundary(conn, x + sub_x, y + sub_y, sub_w, sub_h))\\n', '+            break;\\n', '+\\n', '         vnc_framebuffer_fill(priv->fb, fg,\\n', '                              x + sub_x, y + sub_y, sub_w, sub_h);\\n', '     }\\n'], [' }\\n', ' \\n', ' \\n', '-static gboolean vnc_connection_validate_boundary(VncConnection *conn,\\n', '-                                                 guint16 x, guint16 y,\\n', '-                                                 guint16 width, guint16 height)\\n', '-{\\n', '-    VncConnectionPrivate *priv = conn->priv;\\n', '-\\n', '-    if ((x + width) > priv->width || (y + height) > priv->height) {\\n', '-        vnc_connection_set_error(conn, \"Framebuffer update %dx%d at %d,%d \"\\n', '-                                 \"outside boundary %dx%d\",\\n', '-                                 width, height, x, y, priv->width, priv->height);\\n', '-    }\\n', '-\\n', '-    return !vnc_connection_has_error(conn);\\n', '-}\\n', '-\\n', '-\\n', ' static gboolean vnc_connection_framebuffer_update(VncConnection *conn, gint32 etype,\\n', '                                                   guint16 x, guint16 y,\\n', '                                                   guint16 width, guint16 height)\\n'], ['+/*\\n', '+ * GTK VNC Widget\\n', '+ *\\n', '+ * Copyright (C) 2006  Anthony Liguori <anthony@codemonkey.ws>\\n', '+ * Copyright (C) 2009-2010 Daniel P. Berrange <dan@berrange.com>\\n', '+ *\\n', '+ * This library is free software; you can redistribute it and/or\\n', '+ * modify it under the terms of the GNU Lesser General Public\\n', '+ * License as published by the Free Software Foundation; either\\n', '+ * version 2.0 of the License, or (at your option) any later version.\\n', '+ *\\n', '+ * This library is distributed in the hope that it will be useful,\\n', '+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\\n', '+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\\n', '+ * Lesser General Public License for more details.\\n', '+ *\\n', '+ * You should have received a copy of the GNU Lesser General Public\\n', '+ * License along with this library; if not, write to the Free Software\\n', '+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301 USA\\n', '+ */\\n', '+\\n', '+#include <config.h>\\n', '+\\n', '+#include <string.h>\\n', '+#include <stdlib.h>\\n', '+\\n', '+#include \"vncconnection.h\"\\n', '+#include \"vncbaseframebuffer.h\"\\n', '+\\n', '+static gboolean debug;\\n', '+\\n', '+#if GLIB_CHECK_VERSION(2, 22, 0)\\n', '+\\n', '+struct GVncTest {\\n', '+    GMutex lock;\\n', '+    GMutex clock;\\n', '+    GCond cond;\\n', '+    int port;\\n', '+    VncConnection *conn;\\n', '+    GMainLoop *loop;\\n', '+    gboolean connected;\\n', '+    gboolean quit;\\n', '+    char *error;\\n', '+\\n', '+    char *pixels;\\n', '+\\n', '+    void (*test_func)(GInputStream *, GOutputStream *);\\n', '+};\\n', '+\\n', '+\\n', '+static void test_send_bytes(GOutputStream *os, const guint8 *str, gsize len)\\n', '+{\\n', '+    g_assert(g_output_stream_write_all(os, str, len, NULL, NULL, NULL));\\n', '+}\\n', '+\\n', '+static void test_send_u8(GOutputStream *os, guint8 v)\\n', '+{\\n', '+    g_assert(g_output_stream_write_all(os, &v, 1, NULL, NULL, NULL));\\n', '+}\\n', '+\\n', '+static void test_send_u16(GOutputStream *os, guint16 v)\\n', '+{\\n', '+    v = GUINT16_TO_BE(v);\\n', '+    g_assert(g_output_stream_write_all(os, &v, 2, NULL, NULL, NULL));\\n', '+}\\n', '+\\n', '+static void test_send_u32(GOutputStream *os, guint32 v)\\n', '+{\\n', '+    v = GUINT32_TO_BE(v);\\n', '+    g_assert(g_output_stream_write_all(os, &v, 4, NULL, NULL, NULL));\\n', '+}\\n', '+\\n', '+static void test_send_s32(GOutputStream *os, gint32 v)\\n', '+{\\n', '+    v = GINT32_TO_BE(v);\\n', '+    g_assert(g_output_stream_write_all(os, &v, 4, NULL, NULL, NULL));\\n', '+}\\n', '+\\n', '+static void test_recv_bytes(GInputStream *is, guint8 *str, gsize len)\\n', '+{\\n', '+    g_assert(g_input_stream_read_all(is, str, len, NULL, NULL, NULL));\\n', '+}\\n', '+\\n', '+static void test_recv_u8(GInputStream *is, guint8 v)\\n', '+{\\n', '+    guint8 e;\\n', '+    g_assert(g_input_stream_read_all(is, &e, 1, NULL, NULL, NULL));\\n', '+    g_assert(e == v);\\n', '+}\\n', '+\\n', '+\\n', '+static gpointer test_helper_server(gpointer opaque)\\n', '+{\\n', '+    struct GVncTest *data = opaque;\\n', '+    GSocketListener *server;\\n', '+    GSocketConnection *client;\\n', '+    GIOStream *ios;\\n', '+    GInputStream *is;\\n', '+    GOutputStream *os;\\n', '+\\n', '+    server = g_socket_listener_new();\\n', '+\\n', '+    data->port = g_socket_listener_add_any_inet_port(server, NULL, NULL);\\n', '+    g_mutex_unlock(&data->lock);\\n', '+\\n', '+    client = g_socket_listener_accept(server, NULL, NULL, NULL);\\n', '+\\n', '+    ios = G_IO_STREAM(client);\\n', '+    is = g_io_stream_get_input_stream(ios);\\n', '+    os = g_io_stream_get_output_stream(ios);\\n', '+\\n', '+    guint8 greeting[] = {\\n', \"+        'R', 'F', 'B', ' ',\\n\", \"+        '0', '0', '3', '.',\\n\", \"+        '0', '0', '8', '\\\\n',\\n\", '+    };\\n', '+\\n', '+    /* Greeting */\\n', '+    test_send_bytes(os, greeting, G_N_ELEMENTS(greeting));\\n', '+    test_recv_bytes(is, greeting, G_N_ELEMENTS(greeting));\\n', '+\\n', '+    /* N auth */\\n', '+    test_send_u8(os, 1);\\n', '+    /* auth == none */\\n', '+    test_send_u8(os, 1);\\n', '+    test_recv_u8(is, 1);\\n', '+\\n', '+    /* auth result */\\n', '+    test_send_u32(os, 0);\\n', '+\\n', '+    data->test_func(is, os);\\n', '+\\n', '+    g_mutex_lock(&data->clock);\\n', '+    while (!data->quit) {\\n', '+        g_cond_wait(&data->cond, &data->clock);\\n', '+    }\\n', '+\\n', '+    g_object_unref(client);\\n', '+}\\n', '+\\n', '+static void test_helper_desktop_resize(VncConnection *conn,\\n', '+                                       int width, int height,\\n', '+                                       gpointer opaque)\\n', '+{\\n', '+    struct GVncTest *test = opaque;\\n', '+    const VncPixelFormat *remoteFormat;\\n', '+    VncPixelFormat localFormat = {\\n', '+        .bits_per_pixel = 32,\\n', '+        .depth = 32,\\n', '+        .byte_order = G_BYTE_ORDER,\\n', '+        .true_color_flag = TRUE,\\n', '+        .red_max = 255,\\n', '+        .green_max = 255,\\n', '+        .blue_max = 255,\\n', '+        .red_shift = 0,\\n', '+        .green_shift = 8,\\n', '+        .blue_shift = 16,\\n', '+    };\\n', '+    VncBaseFramebuffer *fb;\\n', '+\\n', '+\\n', '+    VNC_DEBUG(\"Resize %dx%d\", width, height);\\n', '+    remoteFormat = vnc_connection_get_pixel_format(conn);\\n', '+\\n', \"+    /* We'll fix our local copy as rgb888 */\\n\", '+    test->pixels = g_new0(char, width * height * 4);\\n', '+\\n', '+    fb = vnc_base_framebuffer_new(test->pixels, width, height, width * 4,\\n', '+                                  remoteFormat,\\n', '+                                  &localFormat);\\n', '+\\n', '+    vnc_connection_set_framebuffer(conn, VNC_FRAMEBUFFER(fb));\\n', '+\\n', '+    g_object_unref(fb);\\n', '+}\\n', '+\\n', '+\\n', '+static void test_helper_initialized(VncConnection *conn,\\n', '+                                    gpointer opaque)\\n', '+{\\n', '+    struct GVncTest *test = opaque;\\n', '+    gint32 encodings[] = {  VNC_CONNECTION_ENCODING_DESKTOP_RESIZE,\\n', '+                            VNC_CONNECTION_ENCODING_ZRLE,\\n', '+                            VNC_CONNECTION_ENCODING_HEXTILE,\\n', '+                            VNC_CONNECTION_ENCODING_RRE,\\n', '+                            VNC_CONNECTION_ENCODING_COPY_RECT,\\n', '+                            VNC_CONNECTION_ENCODING_RAW };\\n', '+    gint32 *encodingsp;\\n', '+    int n_encodings;\\n', '+\\n', '+    test_helper_desktop_resize(conn,\\n', '+                               vnc_connection_get_width(conn),\\n', '+                               vnc_connection_get_height(conn),\\n', '+                               test);\\n', '+\\n', '+    encodingsp = encodings;\\n', '+    n_encodings = G_N_ELEMENTS(encodings);\\n', '+\\n', '+    VNC_DEBUG(\"Sending %d encodings\", n_encodings);\\n', '+    if (!vnc_connection_set_encodings(conn, n_encodings, encodingsp))\\n', '+        goto error;\\n', '+\\n', '+    VNC_DEBUG(\"Requesting first framebuffer update\");\\n', '+    if (!vnc_connection_framebuffer_update_request(test->conn,\\n', '+                                                   0, 0, 0,\\n', '+                                                   vnc_connection_get_width(test->conn),\\n', '+                                                   vnc_connection_get_height(test->conn)))\\n', '+        vnc_connection_shutdown(test->conn);\\n', '+\\n', '+    test->connected = TRUE;\\n', '+    return;\\n', '+\\n', '+ error:\\n', '+    vnc_connection_shutdown(conn);\\n', '+}\\n', '+\\n', '+static void test_helper_auth_choose_type(VncConnection *conn,\\n', '+                                         GValueArray *types G_GNUC_UNUSED,\\n', '+                                         gpointer opaque G_GNUC_UNUSED)\\n', '+{\\n', '+    vnc_connection_set_auth_type(conn, VNC_CONNECTION_AUTH_NONE);\\n', '+}\\n', '+\\n', '+\\n', '+static void test_helper_disconnected(VncConnection *conn G_GNUC_UNUSED,\\n', '+                                     gpointer opaque)\\n', '+{\\n', '+    struct GVncTest *test = opaque;\\n', '+    g_main_quit(test->loop);\\n', '+}\\n', '+\\n', '+static void test_helper_error(VncConnection *conn,\\n', '+                              const char *str,\\n', '+                              gpointer opaque)\\n', '+{\\n', '+    struct GVncTest *test = opaque;\\n', '+    test->error = g_strdup(str);\\n', '+}\\n', '+\\n', '+static void test_common_bounds_server(GInputStream *is, GOutputStream *os)\\n', '+{\\n', '+    /* Frame buffer width / height */\\n', '+    test_send_u16(os, 100);\\n', '+    test_send_u16(os, 100);\\n', '+\\n', '+    /* BPP, depth, endian, true color */\\n', '+    test_send_u8(os, 32);\\n', '+    test_send_u8(os, 8);\\n', '+    test_send_u8(os, 1);\\n', '+    test_send_u8(os, 1);\\n', '+\\n', '+    /* RGB max + shift*/\\n', '+    test_send_u16(os, 255);\\n', '+    test_send_u16(os, 255);\\n', '+    test_send_u16(os, 255);\\n', '+    test_send_u8(os, 0);\\n', '+    test_send_u8(os, 8);\\n', '+    test_send_u8(os, 16);\\n', '+\\n', '+    guint8 pad[3] = {0};\\n', '+    test_send_bytes(os, pad, G_N_ELEMENTS(pad));\\n', '+\\n', '+    /* name */\\n', \"+    guint8 name[] = { 'T', 'e', 's', 't' };\\n\", '+    test_send_u32(os, G_N_ELEMENTS(name));\\n', '+    test_send_bytes(os, name, G_N_ELEMENTS(name));\\n', '+}\\n', '+\\n', '+static void test_rre_bounds_server(GInputStream *is, GOutputStream *os)\\n', '+{\\n', '+    test_common_bounds_server(is, os);\\n', '+\\n', '+    /* Message type & pad */\\n', '+    test_send_u8(os, 0);\\n', '+    test_send_u8(os, 0);\\n', '+\\n', '+    /* num rect */\\n', '+    test_send_u16(os, 1);\\n', '+    /* x, y, w, h */\\n', '+    test_send_u16(os, 90);\\n', '+    test_send_u16(os, 90);\\n', '+    test_send_u16(os, 10);\\n', '+    test_send_u16(os, 10);\\n', '+\\n', '+    /* encoding=rre */\\n', '+    test_send_s32(os, 2);\\n', '+\\n', '+    /* num rect */\\n', '+    test_send_u32(os, 1);\\n', '+\\n', '+    /* bg pix, fg pix */\\n', '+    test_send_u32(os, 0x41414141);\\n', '+    test_send_u32(os, 0x42424242);\\n', '+\\n', '+    /* x, y, w, h */\\n', '+    test_send_u16(os, 10);\\n', '+    test_send_u16(os, 10000);\\n', '+    test_send_u16(os, 1);\\n', '+    test_send_u16(os, 1);\\n', '+}\\n', '+\\n', '+\\n', '+static void test_hextile_bounds_server(GInputStream *is, GOutputStream *os)\\n', '+{\\n', '+    test_common_bounds_server(is, os);\\n', '+\\n', '+    /* Message type & pad */\\n', '+    test_send_u8(os, 0);\\n', '+    test_send_u8(os, 0);\\n', '+\\n', '+    /* num rect */\\n', '+    test_send_u16(os, 1);\\n', '+    /* x, y, w, h */\\n', '+    test_send_u16(os, 90);\\n', '+    test_send_u16(os, 90);\\n', '+    test_send_u16(os, 10);\\n', '+    test_send_u16(os, 10);\\n', '+\\n', '+    /* encoding=hextile */\\n', '+    test_send_s32(os, 5);\\n', '+\\n', '+    /* tile type */\\n', '+    test_send_u8(os, 0x18);\\n', '+\\n', '+    /* num rect */\\n', '+    test_send_u8(os, 1);\\n', '+\\n', '+    /* fg pix */\\n', '+    test_send_u32(os, 0x12345678);\\n', '+\\n', '+    /* x, y */\\n', '+    test_send_u8(os, 0xff);\\n', '+    test_send_u8(os, 0xff);\\n', '+}\\n', '+\\n', '+\\n', '+static void test_copyrect_bounds_server(GInputStream *is, GOutputStream *os)\\n', '+{\\n', '+    test_common_bounds_server(is, os);\\n', '+\\n', '+    /* Message type & pad */\\n', '+    test_send_u8(os, 0);\\n', '+    test_send_u8(os, 0);\\n', '+\\n', '+    /* num rect */\\n', '+    test_send_u16(os, 1);\\n', '+    /* x, y, w, h */\\n', '+    test_send_u16(os, 90);\\n', '+    test_send_u16(os, 90);\\n', '+    test_send_u16(os, 10);\\n', '+    test_send_u16(os, 10);\\n', '+\\n', '+    /* encoding=copyrect */\\n', '+    test_send_s32(os, 1);\\n', '+\\n', '+    /* src x, y */\\n', '+    test_send_u16(os, 91);\\n', '+    test_send_u16(os, 91);\\n', '+}\\n', '+\\n', '+\\n', '+static void test_validation(void (*test_func)(GInputStream *, GOutputStream *))\\n', '+{\\n', '+    struct GVncTest *test;\\n', '+    char *port;\\n', '+    GMainLoop *loop;\\n', '+    GThread *th;\\n', '+\\n', '+    test = g_new0(struct GVncTest, 1);\\n', '+    test->test_func = test_func;\\n', '+\\n', '+    g_mutex_init(&test->lock);\\n', '+    g_mutex_init(&test->clock);\\n', '+    g_cond_init(&test->cond);\\n', '+    g_mutex_lock(&test->lock);\\n', '+\\n', '+    loop = g_main_loop_new(g_main_context_default(), FALSE);\\n', '+\\n', '+    th = g_thread_new(\"rre-server\", test_helper_server, test);\\n', '+\\n', '+    g_mutex_lock(&test->lock);\\n', '+    port = g_strdup_printf(\"%d\", test->port);\\n', '+\\n', '+    test->conn = vnc_connection_new();\\n', '+\\n', '+    g_signal_connect(test->conn, \"vnc-initialized\",\\n', '+                     G_CALLBACK(test_helper_initialized), test);\\n', '+    g_signal_connect(test->conn, \"vnc-disconnected\",\\n', '+                     G_CALLBACK(test_helper_disconnected), test);\\n', '+    g_signal_connect(test->conn, \"vnc-auth-choose-type\",\\n', '+                     G_CALLBACK(test_helper_auth_choose_type), test);\\n', '+    g_signal_connect(test->conn, \"vnc-desktop-resize\",\\n', '+                     G_CALLBACK(test_helper_desktop_resize), test);\\n', '+    g_signal_connect(test->conn, \"vnc-error\",\\n', '+                     G_CALLBACK(test_helper_error), test);\\n', '+\\n', '+    vnc_connection_open_host(test->conn, \"127.0.0.1\", port);\\n', '+\\n', '+    test->loop = g_main_loop_new(g_main_context_default(), FALSE);\\n', '+\\n', '+    g_main_loop_run(test->loop);\\n', '+\\n', '+    g_mutex_lock(&test->clock);\\n', '+    test->quit = TRUE;\\n', '+    g_mutex_unlock(&test->clock);\\n', '+    g_cond_signal(&test->cond);\\n', '+\\n', '+    g_thread_join(th);\\n', '+\\n', '+    vnc_connection_shutdown(test->conn);\\n', '+    g_object_unref(test->conn);\\n', '+    g_free(test->pixels);\\n', '+    g_main_loop_unref(test->loop);\\n', '+\\n', '+    g_assert(test->error);\\n', '+    if (debug)\\n', '+        g_printerr(\"Got err %s\\\\n\", test->error);\\n', '+    g_free(test->error);\\n', '+\\n', '+    g_free(port);\\n', '+    g_free(test);\\n', '+}\\n', '+\\n', '+static void test_validation_rre(void)\\n', '+{\\n', '+    test_validation(test_rre_bounds_server);\\n', '+}\\n', '+\\n', '+static void test_validation_hextile(void)\\n', '+{\\n', '+    test_validation(test_hextile_bounds_server);\\n', '+}\\n', '+\\n', '+static void test_validation_copyrect(void)\\n', '+{\\n', '+    test_validation(test_copyrect_bounds_server);\\n', '+}\\n', '+#endif\\n', '+\\n', '+int main(int argc, char **argv) {\\n', '+    g_test_init(&argc, &argv, NULL);\\n', '+\\n', '+    if (getenv(\"GTK_VNC_DEBUG\")) {\\n', '+        debug = TRUE;\\n', '+        vnc_util_set_debug(TRUE);\\n', '+    }\\n', '+\\n', '+#if GLIB_CHECK_VERSION(2, 22, 0)\\n', '+    g_test_add_func(\"/conn/validation/rre\", test_validation_rre);\\n', '+    g_test_add_func(\"/conn/validation/copyrect\", test_validation_copyrect);\\n', '+    g_test_add_func(\"/conn/validation/hextile\", test_validation_hextile);\\n', '+#endif\\n', '+\\n', '+    return g_test_run();\\n', '+}\\n', '+/*\\n', '+ * Local variables:\\n', '+ *  c-indent-level: 4\\n', '+ *  c-basic-offset: 4\\n', '+ *  indent-tabs-mode: nil\\n', '+ * End:\\n', '+ */\\n']]),\n",
       "        1],\n",
       "       [list(['\\n', 'Problem: An application violating the architectural rules regarding\\n', 'operation dependencies and having specific Register Stack Engine (RSE)\\n', 'state at the time of the violation, may result in an illegal operation\\n', 'fault and invalid RSE state.  Such faults may initiate a cascade of\\n', 'repeated illegal operation faults within OS interruption handlers.\\n', 'The specific behavior is OS dependent.\\n', '\\n', 'Implication: An application causing an illegal operation fault with\\n', 'specific RSE state may result in a series of illegal operation faults\\n', 'and an eventual OS stack overflow condition.\\n', '\\n', 'Workaround: OS interruption handlers that switch to kernel backing\\n', 'store implement a check for invalid RSE state to avoid the series\\n', 'of illegal operation faults.\\n', '\\n', 'The core of the workaround is the RSE_WORKAROUND code sequence\\n', 'inserted into each invocation of the SAVE_MIN_WITH_COVER and\\n', 'SAVE_MIN_WITH_COVER_R19 macros.  This sequence includes hard-coded\\n', 'constants that depend on the number of stacked physical registers\\n', 'being 96.  The rest of this patch consists of code to disable this\\n', 'workaround should this not be the case (with the presumption that\\n', 'if a future Itanium processor increases the number of registers, it\\n', 'would also remove the need for this patch).\\n', '\\n', 'Move the start of the RBS up to a mod32 boundary to avoid some\\n', 'corner cases.\\n', '\\n', 'The dispatch_illegal_op_fault code outgrew the spot it was\\n', 'squatting in when built with this patch and CONFIG_VIRT_CPU_ACCOUNTING=y\\n', 'Move it out to the end of the ivt.\\n', '\\n', 'Signed-off-by: Tony Luck <tony.luck@intel.com>\\n']),\n",
       "        list([[' \\tDBG_FAULT(15)\\n', ' \\tFAULT(15)\\n', ' \\n', '-\\t/*\\n', '-\\t * Squatting in this space ...\\n', '-\\t *\\n', '-\\t * This special case dispatcher for illegal operation faults allows preserved\\n', '-\\t * registers to be modified through a callback function (asm only) that is handed\\n', '-\\t * back from the fault handler in r8. Up to three arguments can be passed to the\\n', '-\\t * callback function by returning an aggregate with the callback as its first\\n', '-\\t * element, followed by the arguments.\\n', '-\\t */\\n', '-ENTRY(dispatch_illegal_op_fault)\\n', '-\\t.prologue\\n', '-\\t.body\\n', '-\\tSAVE_MIN_WITH_COVER\\n', '-\\tssm psr.ic | PSR_DEFAULT_BITS\\n', '-\\t;;\\n', '-\\tsrlz.i\\t\\t// guarantee that interruption collection is on\\n', '-\\t;;\\n', '-(p15)\\tssm psr.i\\t// restore psr.i\\n', '-\\tadds r3=8,r2\\t// set up second base pointer for SAVE_REST\\n', '-\\t;;\\n', '-\\talloc r14=ar.pfs,0,0,1,0\\t// must be first in insn group\\n', '-\\tmov out0=ar.ec\\n', '-\\t;;\\n', '-\\tSAVE_REST\\n', '-\\tPT_REGS_UNWIND_INFO(0)\\n', '-\\t;;\\n', '-\\tbr.call.sptk.many rp=ia64_illegal_op_fault\\n', '-.ret0:\\t;;\\n', '-\\talloc r14=ar.pfs,0,0,3,0\\t// must be first in insn group\\n', '-\\tmov out0=r9\\n', '-\\tmov out1=r10\\n', '-\\tmov out2=r11\\n', '-\\tmovl r15=ia64_leave_kernel\\n', '-\\t;;\\n', '-\\tmov rp=r15\\n', '-\\tmov b6=r8\\n', '-\\t;;\\n', '-\\tcmp.ne p6,p0=0,r8\\n', '-(p6)\\tbr.call.dpnt.many b6=b6\\t\\t// call returns to ia64_leave_kernel\\n', '-\\tbr.sptk.many ia64_leave_kernel\\n', '-END(dispatch_illegal_op_fault)\\n', '-\\n', ' \\t.org ia64_ivt+0x4000\\n', ' /////////////////////////////////////////////////////////////////////////////////////////\\n', ' // 0x4000 Entry 16 (size 64 bundles) Reserved\\n'], [' \\tDBG_FAULT(67)\\n', ' \\tFAULT(67)\\n', ' \\n', '+\\t/*\\n', '+\\t * Squatting in this space ...\\n', '+\\t *\\n', '+\\t * This special case dispatcher for illegal operation faults allows preserved\\n', '+\\t * registers to be modified through a callback function (asm only) that is handed\\n', '+\\t * back from the fault handler in r8. Up to three arguments can be passed to the\\n', '+\\t * callback function by returning an aggregate with the callback as its first\\n', '+\\t * element, followed by the arguments.\\n', '+\\t */\\n', '+ENTRY(dispatch_illegal_op_fault)\\n', '+\\t.prologue\\n', '+\\t.body\\n', '+\\tSAVE_MIN_WITH_COVER\\n', '+\\tssm psr.ic | PSR_DEFAULT_BITS\\n', '+\\t;;\\n', '+\\tsrlz.i\\t\\t// guarantee that interruption collection is on\\n', '+\\t;;\\n', '+(p15)\\tssm psr.i\\t// restore psr.i\\n', '+\\tadds r3=8,r2\\t// set up second base pointer for SAVE_REST\\n', '+\\t;;\\n', '+\\talloc r14=ar.pfs,0,0,1,0\\t// must be first in insn group\\n', '+\\tmov out0=ar.ec\\n', '+\\t;;\\n', '+\\tSAVE_REST\\n', '+\\tPT_REGS_UNWIND_INFO(0)\\n', '+\\t;;\\n', '+\\tbr.call.sptk.many rp=ia64_illegal_op_fault\\n', '+.ret0:\\t;;\\n', '+\\talloc r14=ar.pfs,0,0,3,0\\t// must be first in insn group\\n', '+\\tmov out0=r9\\n', '+\\tmov out1=r10\\n', '+\\tmov out2=r11\\n', '+\\tmovl r15=ia64_leave_kernel\\n', '+\\t;;\\n', '+\\tmov rp=r15\\n', '+\\tmov b6=r8\\n', '+\\t;;\\n', '+\\tcmp.ne p6,p0=0,r8\\n', '+(p6)\\tbr.call.dpnt.many b6=b6\\t\\t// call returns to ia64_leave_kernel\\n', '+\\tbr.sptk.many ia64_leave_kernel\\n', '+END(dispatch_illegal_op_fault)\\n', '+\\n', ' #ifdef CONFIG_IA32_SUPPORT\\n', ' \\n', ' \\t/*\\n'], [' #define ACCOUNT_SYS_ENTER\\n', ' #endif\\n', ' \\n', '+.section \".data.patch.rse\", \"a\"\\n', '+.previous\\n', '+\\n', ' /*\\n', '  * DO_SAVE_MIN switches to the kernel stacks (if necessary) and saves\\n', '  * the minimum state necessary that allows us to turn psr.ic back\\n'], ['  * Note that psr.ic is NOT turned on by this macro.  This is so that\\n', '  * we can pass interruption state as arguments to a handler.\\n', '  */\\n', '-#define DO_SAVE_MIN(COVER,SAVE_IFS,EXTRA)\\t\\t\\t\\t\\t\\t\\t\\\\\\n', '+#define DO_SAVE_MIN(COVER,SAVE_IFS,EXTRA,WORKAROUND)\\t\\t\\t\\t\\t\\t\\\\\\n', ' \\tmov r16=IA64_KR(CURRENT);\\t/* M */\\t\\t\\t\\t\\t\\t\\t\\\\\\n', ' \\tmov r27=ar.rsc;\\t\\t\\t/* M */\\t\\t\\t\\t\\t\\t\\t\\\\\\n', ' \\tmov r20=r1;\\t\\t\\t/* A */\\t\\t\\t\\t\\t\\t\\t\\\\\\n'], [' \\ttbit.nz p15,p0=r29,IA64_PSR_I_BIT;\\t\\t\\t\\t\\t\\t\\t\\\\\\n', ' \\tmov r29=b0\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n', ' \\t;;\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n', '+\\tWORKAROUND;\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n', ' \\tadds r16=PT(R8),r1;\\t/* initialize first base pointer */\\t\\t\\t\\t\\\\\\n', ' \\tadds r17=PT(R9),r1;\\t/* initialize second base pointer */\\t\\t\\t\\t\\\\\\n', \" (pKStk)\\tmov r18=r0;\\t\\t/* make sure r18 isn't NaT */\\t\\t\\t\\t\\t\\\\\\n\"], [' \\tst8 [r25]=r10;      \\t/* ar.ssd */\\t\\\\\\n', ' \\t;;\\n', ' \\n', '-#define SAVE_MIN_WITH_COVER\\tDO_SAVE_MIN(cover, mov r30=cr.ifs,)\\n', '-#define SAVE_MIN_WITH_COVER_R19\\tDO_SAVE_MIN(cover, mov r30=cr.ifs, mov r15=r19)\\n', '-#define SAVE_MIN\\t\\tDO_SAVE_MIN(     , mov r30=r0, )\\n', '+#define RSE_WORKAROUND\\t\\t\\t\\t\\\\\\n', '+(pUStk) extr.u r17=r18,3,6;\\t\\t\\t\\\\\\n', '+(pUStk)\\tsub r16=r18,r22;\\t\\t\\t\\\\\\n', '+[1:](pKStk)\\tbr.cond.sptk.many 1f;\\t\\t\\\\\\n', '+\\t.xdata4 \".data.patch.rse\",1b-.\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+\\tcmp.ge p6,p7 = 33,r17;\\t\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+(p6)\\tmov r17=0x310;\\t\\t\\t\\t\\\\\\n', '+(p7)\\tmov r17=0x308;\\t\\t\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+\\tcmp.leu p1,p0=r16,r17;\\t\\t\\t\\\\\\n', '+(p1)\\tbr.cond.sptk.many 1f;\\t\\t\\t\\\\\\n', '+\\tdep.z r17=r26,0,62;\\t\\t\\t\\\\\\n', '+\\tmovl r16=2f;\\t\\t\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+\\tmov ar.pfs=r17;\\t\\t\\t\\t\\\\\\n', '+\\tdep r27=r0,r27,16,14;\\t\\t\\t\\\\\\n', '+\\tmov b0=r16;\\t\\t\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+\\tbr.ret.sptk b0;\\t\\t\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+2:\\t\\t\\t\\t\\t\\t\\\\\\n', '+\\tmov ar.rsc=r0\\t\\t\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+\\tflushrs;\\t\\t\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+\\tmov ar.bspstore=r22\\t\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+\\tmov r18=ar.bsp;\\t\\t\\t\\t\\\\\\n', '+\\t;;\\t\\t\\t\\t\\t\\\\\\n', '+1:\\t\\t\\t\\t\\t\\t\\\\\\n', '+\\t.pred.rel \"mutex\", pKStk, pUStk\\n', '+\\n', '+#define SAVE_MIN_WITH_COVER\\tDO_SAVE_MIN(cover, mov r30=cr.ifs, , RSE_WORKAROUND)\\n', '+#define SAVE_MIN_WITH_COVER_R19\\tDO_SAVE_MIN(cover, mov r30=cr.ifs, mov r15=r19, RSE_WORKAROUND)\\n', '+#define SAVE_MIN\\t\\t\\tDO_SAVE_MIN(     , mov r30=r0, , )\\n'], [' \\tia64_srlz_i();\\n', ' }\\n', ' \\n', '+/*\\n', '+ * Disable the RSE workaround by turning the conditional branch\\n', '+ * that we tagged in each place the workaround was used into an\\n', '+ * unconditional branch.\\n', '+ */\\n', '+void __init\\n', '+ia64_patch_rse (unsigned long start, unsigned long end)\\n', '+{\\n', '+\\ts32 *offp = (s32 *) start;\\n', '+\\tu64 ip, *b;\\n', '+\\n', '+\\twhile (offp < (s32 *) end) {\\n', '+\\t\\tip = (u64) offp + *offp;\\n', '+\\n', '+\\t\\tb = (u64 *)(ip & -16);\\n', '+\\t\\tb[1] &= ~0xf800000L;\\n', '+\\t\\tia64_fc((void *) ip);\\n', '+\\t\\t++offp;\\n', '+\\t}\\n', '+\\tia64_sync_i();\\n', '+\\tia64_srlz_i();\\n', '+}\\n', '+\\n', ' void __init\\n', ' ia64_patch_mckinley_e9 (unsigned long start, unsigned long end)\\n', ' {\\n'], [' \\t/* process SAL system table: */\\n', ' \\tia64_sal_init(__va(efi.sal_systab));\\n', ' \\n', '+#ifdef CONFIG_ITANIUM\\n', '+\\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\\n', '+#else\\n', '+\\t{\\n', '+\\t\\tu64 num_phys_stacked;\\n', '+\\n', '+\\t\\tif (ia64_pal_rse_info(&num_phys_stacked, 0) == 0 && num_phys_stacked > 96)\\n', '+\\t\\t\\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\\n', '+\\t}\\n', '+#endif\\n', '+\\n', ' #ifdef CONFIG_SMP\\n', ' \\tcpu_physical_id(0) = hard_smp_processor_id();\\n', ' #endif\\n'], [' \\t  __end___vtop_patchlist = .;\\n', ' \\t}\\n', ' \\n', '+  .data.patch.rse : AT(ADDR(.data.patch.rse) - LOAD_OFFSET)\\n', '+\\t{\\n', '+\\t  __start___rse_patchlist = .;\\n', '+\\t  *(.data.patch.rse)\\n', '+\\t  __end___rse_patchlist = .;\\n', '+\\t}\\n', '+\\n', '   .data.patch.mckinley_e9 : AT(ADDR(.data.patch.mckinley_e9) - LOAD_OFFSET)\\n', ' \\t{\\n', ' \\t  __start___mckinley_e9_bundles = .;\\n'], [' extern void ia64_patch_mckinley_e9 (unsigned long start, unsigned long end);\\n', ' extern void ia64_patch_vtop (unsigned long start, unsigned long end);\\n', ' extern void ia64_patch_phys_stack_reg(unsigned long val);\\n', '+extern void ia64_patch_rse (unsigned long start, unsigned long end);\\n', ' extern void ia64_patch_gate (void);\\n', ' \\n', ' #endif /* _ASM_IA64_PATCH_H */\\n'], [' # define KERNEL_STACK_SIZE_ORDER\\t\\t0\\n', ' #endif\\n', ' \\n', '-#define IA64_RBS_OFFSET\\t\\t\\t((IA64_TASK_SIZE + IA64_THREAD_INFO_SIZE + 15) & ~15)\\n', '+#define IA64_RBS_OFFSET\\t\\t\\t((IA64_TASK_SIZE + IA64_THREAD_INFO_SIZE + 31) & ~31)\\n', ' #define IA64_STK_OFFSET\\t\\t\\t((1 << KERNEL_STACK_SIZE_ORDER)*PAGE_SIZE)\\n', ' \\n', ' #define KERNEL_STACK_SIZE\\t\\tIA64_STK_OFFSET\\n'], [' \\n', ' extern char __per_cpu_start[], __per_cpu_end[], __phys_per_cpu_start[];\\n', ' extern char __start___vtop_patchlist[], __end___vtop_patchlist[];\\n', '+extern char __start___rse_patchlist[], __end___rse_patchlist[];\\n', ' extern char __start___mckinley_e9_bundles[], __end___mckinley_e9_bundles[];\\n', ' extern char __start___phys_stack_reg_patchlist[], __end___phys_stack_reg_patchlist[];\\n', ' extern char __start_gate_section[];\\n']]),\n",
       "        1],\n",
       "       ...,\n",
       "       [list(['\\n', '    Tidied up memory freeing a bit.\\n', '    \\n', '    \\n', '    git-svn-id: http://svn.zoneminder.com/svn/zm/trunk@3297 e3e1d417-86f3-4887-817a-d78f3d33393f\\n', '\\n']),\n",
       "        list([[' \\t{\\n', ' \\t\\tdelete monitors[i];\\n', ' \\t}\\n', '+    delete monitors;\\n', '+\\tdelete [] alarm_capture_delays;\\n', ' \\tdelete [] capture_delays;\\n', ' \\tdelete [] next_delays;\\n', ' \\tdelete [] last_capture_times;\\n', '\\n']]),\n",
       "        0],\n",
       "       [list(['\\n', '    added CMD_QUIT to kill zms via command\\n', '\\n']),\n",
       "        list([['             Debug( 1, \"Got QUERY command, sending STATUS\" );\\n', '             break;\\n', '         }\\n', '+\\tcase CMD_QUIT :\\n', '+        {\\n', '+           Info (\"User initiated exit - CMD_QUIT\");\\n', '+           break;\\n', '+        }\\n', '         default :\\n', '         {\\n', '             // Do nothing, for now\\n'], ['             exit( -1 );\\n', '         }\\n', '     }\\n', '+    // quit after sending a status, if this was a quit request\\n', '+    if ((MsgCommand)msg->msg_data[0]==CMD_QUIT)\\n', '+        exit(0);\\n', ' \\n', '     updateFrameRate( (double)event_data->frame_count/event_data->duration );\\n', ' }\\n', '\\n']]),\n",
       "        0],\n",
       "       [list(['\\n', '    Save 1 or more calls to time(NULL)\\n', '\\n']),\n",
       "        list([['     Debug( 2, \"RTSP Rtptime is %ld\", rtpTime );\\n', ' \\n', '     time_t lastKeepalive = time(NULL);\\n', '+\\ttime_t now;\\n', '     message = \"GET_PARAMETER \"+mUrl+\" RTSP/1.0\\\\r\\\\nSession: \"+session+\"\\\\r\\\\n\";\\n', ' \\n', '     switch( mMethod )\\n'], [' \\n', '             while( !mStop )\\n', '             {\\n', '+\\t\\t\\t\\tnow = time(NULL);\\n', '                 // Send a keepalive message if the server supports this feature and we are close to the timeout expiration\\n', '-                if ( sendKeepalive && (timeout > 0) && ((time(NULL)-lastKeepalive) > (timeout-5)) )\\n', '+Debug(5, \"sendkeepalibe %d, timeout %d, now: %d last: %d since: %d\", sendKeepalive, timeout, now, lastKeepalive, (now-lastKeepalive) );\\n', '+                if ( sendKeepalive && (timeout > 0) && ((now-lastKeepalive) > (timeout-5)) )\\n', '                 {\\n', '                     if ( !sendCommand( message ) )\\n', '                         return( -1 );\\n', '-                    lastKeepalive = time(NULL);\\n', '+                    lastKeepalive = now;\\n', '                 }\\n', '                 usleep( 100000 );\\n', '             }\\n'], ['                 }\\n', '                 // Send a keepalive message if the server supports this feature and we are close to the timeout expiration\\n', '                 // FIXME: Is this really necessary when using tcp ?\\n', '-                if ( sendKeepalive && (timeout > 0) && ((time(NULL)-lastKeepalive) > (timeout-5)) )\\n', '+\\t\\t\\t\\tnow = time(NULL);\\n', '+                // Send a keepalive message if the server supports this feature and we are close to the timeout expiration\\n', '+Debug(5, \"sendkeepalibe %d, timeout %d, now: %d last: %d since: %d\", sendKeepalive, timeout, now, lastKeepalive, (now-lastKeepalive) );\\n', '+                if ( sendKeepalive && (timeout > 0) && ((now-lastKeepalive) > (timeout-5)) )\\n', '                 {\\n', '                     if ( !sendCommand( message ) )\\n', '                         return( -1 );\\n', '-                    lastKeepalive = time(NULL);\\n', '+                    lastKeepalive = now;\\n', '                 }\\n', '                 buffer.tidy( 1 );\\n', '             }\\n', '\\n']]),\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load('data.npy',allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwinRNNTrain(dataTrain, labelTrain, dataTest, labelTest, preWTwin=twinPreWeights, preWMsg=msgPreWeights,\n",
    "                             batchsize=_TRnnBatchSz_, learnRate=_TRnnLearnRt_, dTest=dataTest, lTest=labelTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(data, labels, setType, rate=0.2):\n",
    "    '''\n",
    "    Split the data and labels into two sets with a specific rate.\n",
    "    :param data: feature data.\n",
    "    [[[n, {0~5}, {-1~1}], ...], ...]\n",
    "    [[[n, 0/1, 0/1, 0/1, 0/1, 0/1, {-1~1}], ...], ...]\n",
    "    :param labels: labels. [[0/1], ...]\n",
    "    :param setType: the splited dataset type.\n",
    "    :param rate: the split rate. 0 ~ 1\n",
    "    :return: dsetRest - the rest dataset.\n",
    "             lsetRest - the rest labels.\n",
    "             dset - the splited dataset.\n",
    "             lset - the splited labels.\n",
    "    '''\n",
    "\n",
    "    # set parameters.\n",
    "    setType = setType.upper()\n",
    "    numData = len(data)\n",
    "    num = math.floor(numData * rate)\n",
    "\n",
    "    # get the random data list.\n",
    "    if (os.path.exists(tempPath + '/split_' + setType + '.npy')) & (_LOCK_):\n",
    "        dataList = np.load(tempPath + '/split_' + setType + '.npy')\n",
    "    else:\n",
    "        dataList = list(range(numData))\n",
    "        random.shuffle(dataList)\n",
    "        np.save(tempPath + '/split_' + setType + '.npy', dataList, allow_pickle=True)\n",
    "\n",
    "    # split data.\n",
    "    dset = data[dataList[0:num]]\n",
    "    lset = labels[dataList[0:num]]\n",
    "    dsetRest = data[dataList[num:]]\n",
    "    lsetRest = labels[dataList[num:]]\n",
    "\n",
    "    # print.\n",
    "    setTypeRest = 'TRAIN' if (setType == 'VALID') else 'REST'\n",
    "    print('[INFO] <SplitData> Split data into ' + str(len(dsetRest)) + ' ' + setTypeRest\n",
    "          + ' dataset and ' + str(len(dset)) + ' ' + setType + ' dataset. (Total: '\n",
    "          + str(len(dsetRest) + len(dset)) + ', Rate: ' + str(int(rate * 100)) + '%)')\n",
    "\n",
    "    return dsetRest, lsetRest, dset, lset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SplitData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m label \u001b[38;5;241m=\u001b[39m smellKey\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Split data into train/test dataset\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dataTrain, labelTrain, dataTest, labelTest \u001b[38;5;241m=\u001b[39m \u001b[43mSplitData\u001b[49m(twinData, label, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[INFO] <demoTwin> Get \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataTrain)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m TRAIN data, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataTest))\n\u001b[0;32m      8\u001b[0m       \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m TEST data. (Total: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataTrain) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataTest)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load or train TwinRNN model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SplitData' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine old and fixed embeddings\n",
    "twinData = np.concatenate((old_embeddings, fixed_embeddings), axis=1)\n",
    "label = smellKey\n",
    "\n",
    "# Split data into train/test dataset\n",
    "dataTrain, labelTrain, dataTest, labelTest = SplitData(twinData, label, 'test', rate=0.2)\n",
    "print('[INFO] <demoTwin> Get ' + str(len(dataTrain)) + ' TRAIN data, ' + str(len(dataTest))\n",
    "      + ' TEST data. (Total: ' + str(len(dataTrain) + len(dataTest)) + ')')\n",
    "\n",
    "\n",
    "model = TwinRNNTrain(dataTrain, labelTrain, dataTest, labelTest, preWTwin=twinPreWeights, preWMsg=msgPreWeights,\n",
    "                         batchsize=_TRnnBatchSz_, learnRate=_TRnnLearnRt_, dTest=dataTest, lTest=labelTest)\n",
    "\n",
    "# Test TwinRNN model\n",
    "predictions, accuracy = TwinRNNTest(model, dataTest, labelTest, batchsize=_TRnnBatchSz_)\n",
    "_, confusion = OutputEval(predictions, labelTest, 'TwinRNN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwinRNN(nn.Module):\n",
    "    '''\n",
    "    TwinRNN : convert a patch data into a predicted label.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, preWTwin, preWMsg, hidSizTwin=32, hidSizMsg=32, hidLayTwin=1, hidLayMsg=1):\n",
    "        '''\n",
    "        define each layer in the network model.\n",
    "        :param preWTwin: tensor pre-trained weights for embedding layer for twin.\n",
    "        :param preWMsg: tensor pre-trained weights for embedding layer for msg.\n",
    "        :param hidSizTwin: node number in the hidden layer for twin.\n",
    "        :param hidSizMsg: node number in the hidden layer for msg.\n",
    "        :param hidLayTwin: number of hidden layer for twin.\n",
    "        :param hidLayMsg: number of hidden layer for msg.\n",
    "        '''\n",
    "\n",
    "        super(TwinRNN, self).__init__()\n",
    "        # parameters.\n",
    "        class_num = 2\n",
    "    # twin.\n",
    "        vSizTwin, emDimTwin = preWTwin.size()\n",
    "        # Embedding Layer for twin.\n",
    "        self.embedTwin = nn.Embedding(num_embeddings=vSizTwin, embedding_dim=emDimTwin)\n",
    "        self.embedTwin.load_state_dict({'weight': preWTwin})\n",
    "        self.embedTwin.weight.requires_grad = True\n",
    "        # LSTM Layer for twin.\n",
    "        if _DEBUG_: print(_TwinExtraDim_)\n",
    "        self.lstmTwin = nn.LSTM(input_size=emDimTwin+_TwinExtraDim_, hidden_size=hidSizTwin, num_layers=hidLayTwin, bidirectional=True)\n",
    "    # msg.\n",
    "        vSizMsg, emDimMsg = preWMsg.size()\n",
    "        # Embedding Layer for msg.\n",
    "        self.embedMsg = nn.Embedding(num_embeddings=vSizMsg, embedding_dim=emDimMsg)\n",
    "        self.embedMsg.load_state_dict({'weight': preWMsg})\n",
    "        self.embedMsg.weight.requires_grad = True\n",
    "        # LSTM Layer for msg.\n",
    "        self.lstmMsg = nn.LSTM(input_size=emDimMsg, hidden_size=hidSizMsg, num_layers=hidLayMsg, bidirectional=True)\n",
    "    # common.\n",
    "        # Fully-Connected Layer.\n",
    "        self.fc1 = nn.Linear(hidSizTwin * hidLayTwin * 4, hidSizTwin * hidLayTwin * 2)\n",
    "        self.fc2 = nn.Linear(hidSizTwin * hidLayTwin * 2, class_num)\n",
    "        self.fc3 = nn.Linear((hidSizTwin * hidLayTwin + hidSizMsg * hidLayMsg) * 2, hidSizTwin * hidLayTwin + hidSizMsg * hidLayMsg)\n",
    "        self.fc4 = nn.Linear(hidSizTwin * hidLayTwin + hidSizMsg * hidLayMsg, class_num)\n",
    "        # Softmax non-linearity.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        convert inputs to predictions.\n",
    "        :param x: input tensor. dimension: batch_size * twin_length * feature_dim.\n",
    "        :return: self.softmax(final_out) - predictions.\n",
    "        [[0.3, 0.7], [0.2, 0.8], ...]\n",
    "        '''\n",
    "\n",
    "    # twin 1.\n",
    "        xTwin = x[:, :_TwinMaxLen_, :6]\n",
    "        # xTwin         batch_size * twin_length * feature_dim\n",
    "        #print(xTwin.size())\n",
    "        embedsTwin = self.embedTwin(xTwin[:, :, 0])\n",
    "        # embedsTwin    batch_size * twin_length * embed_dim_twin\n",
    "        features = xTwin[:, :, 1:]\n",
    "        # features      batch_size * twin_length * _TwinExtraDim_\n",
    "        inputsTwin = torch.cat((embedsTwin.float(), features.float()), 2)\n",
    "        #print(inputsTwin.size())\n",
    "        # inputsTwin    batch_size * twin_length * (embed_dim_twin + _TwinExtraDim_)\n",
    "        inputsTwin = inputsTwin.permute(1, 0, 2)\n",
    "        # inputsTwin    twin_length * batch_size * (embed_dim_twin + _TwinExtraDim_)\n",
    "        lstm_out, (h_n, c_n) = self.lstmTwin(inputsTwin)\n",
    "        # lstm_out      twin_length * batch_size * (hidden_size * direction_num)\n",
    "        # h_n           (num_layers * direction_num) * batch_size * hidden_size\n",
    "        # h_n           (num_layers * direction_num) * batch_size * hidden_size\n",
    "        featMapTwin1 = torch.cat([h_n[i, :, :] for i in range(h_n.shape[0])], dim=1)\n",
    "        # featMapTwin1   batch_size * (hidden_size * num_layers * direction_num)\n",
    "        #print(featMapTwin1)\n",
    "    # twin 2.\n",
    "        xTwin = x[:, :_TwinMaxLen_, 6:-1]\n",
    "        # xTwin         batch_size * twin_length * feature_dim\n",
    "        #print(xTwin.size())\n",
    "        embedsTwin = self.embedTwin(xTwin[:, :, 0])\n",
    "        # embedsTwin    batch_size * twin_length * embed_dim_twin\n",
    "        features = xTwin[:, :, 1:]\n",
    "        # features      batch_size * twin_length * _TwinExtraDim_\n",
    "        inputsTwin = torch.cat((embedsTwin.float(), features.float()), 2)\n",
    "        #print(inputsTwin.size())\n",
    "        # inputsTwin    batch_size * twin_length * (embed_dim_twin + _TwinExtraDim_)\n",
    "        inputsTwin = inputsTwin.permute(1, 0, 2)\n",
    "        # inputsTwin    twin_length * batch_size * (embed_dim_twin + _TwinExtraDim_)\n",
    "        lstm_out, (h_n, c_n) = self.lstmTwin(inputsTwin)\n",
    "        # lstm_out      twin_length * batch_size * (hidden_size * direction_num)\n",
    "        # h_n           (num_layers * direction_num) * batch_size * hidden_size\n",
    "        # h_n           (num_layers * direction_num) * batch_size * hidden_size\n",
    "        featMapTwin2 = torch.cat([h_n[i, :, :] for i in range(h_n.shape[0])], dim=1)\n",
    "        # featMapTwin2   batch_size * (hidden_size * num_layers * direction_num)\n",
    "        #print(featMapTwin2)\n",
    "    # msg.\n",
    "        xMsg = x[:, :_MsgMaxLen_, -1]\n",
    "        # xMsg          batch_size * msg_length * 1\n",
    "        # print(xMsg.size())\n",
    "        embedsMsg = self.embedMsg(xMsg)\n",
    "        # embedsMsg     batch_size * msg_length * embed_dim_msg\n",
    "        inputsMsg = embedsMsg.permute(1, 0, 2)\n",
    "        # inputsMsg     msg_length * batch_size * (embed_dim_msg)\n",
    "        lstm_out, (h_n, c_n) = self.lstmMsg(inputsMsg)\n",
    "        # lstm_out      msg_length * batch_size * (hidden_size * direction_num)\n",
    "        # h_n           (num_layers * direction_num) * batch_size * hidden_size\n",
    "        # h_n           (num_layers * direction_num) * batch_size * hidden_size\n",
    "        featMapMsg = torch.cat([h_n[i, :, :] for i in range(h_n.shape[0])], dim=1)\n",
    "        # featMapMsg    batch_size * (hidden_size * num_layers * direction_num)\n",
    "        #print(featMapMsg.size())\n",
    "    # common.\n",
    "        # combine twins.\n",
    "        featMap = torch.cat((featMapTwin1, featMapTwin2), dim=1)\n",
    "        # fc layers.\n",
    "        featMap = self.fc1(featMap)\n",
    "        if (0 == _TWIN_): # (only twins).\n",
    "            final_out = self.fc2(featMap)\n",
    "        elif (1 == _TWIN_): # (twins + msg).\n",
    "            # combine twins + msg.\n",
    "            featMap = torch.cat((featMap, featMapMsg), dim=1)\n",
    "            # fc 2 layers.\n",
    "            featMap = self.fc3(featMap)\n",
    "            final_out = self.fc4(featMap)\n",
    "        #print(final_out.size())\n",
    "        return self.softmax(final_out)      # batch_size * class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwinRNNTrain(dTrain, lTrain, dValid, lValid, preWTwin, preWMsg, batchsize=64, learnRate=0.001, dTest=None, lTest=None):\n",
    "    '''\n",
    "    Train the TwinRNN model.\n",
    "    :param dTrain: training data. [[n, ...], ...]\n",
    "    :param lTrain: training label. [[n, ...], ...]\n",
    "    :param dValid: validation data. [[n, ...], ...]\n",
    "    :param lValid: validation label. [[n, ...], ...]\n",
    "    :param preWDiff: pre-trained weights for diff embedding layer.\n",
    "    :param preWMsg: pre-trained weights for msg embedding layer.\n",
    "    :param batchsize: number of samples in a batch.\n",
    "    :param learnRate: learning rate.\n",
    "    :param dTest: test data. [[n, ...], ...]\n",
    "    :param lTest: test label. [[n, ...], ...]\n",
    "    :return: model - the TwinRNN model.\n",
    "    '''\n",
    "\n",
    "    # get the mark of the test dataset.\n",
    "    if dTest is None: dTest = []\n",
    "    if lTest is None: lTest = []\n",
    "    markTest = 1 if (len(dTest)) & (len(lTest)) else 0\n",
    "\n",
    "    # tensor data processing.\n",
    "    xTrain = torch.from_numpy(dTrain).long().cuda()\n",
    "    yTrain = torch.from_numpy(lTrain).long().cuda()\n",
    "    xValid = torch.from_numpy(dValid).long().cuda()\n",
    "    yValid = torch.from_numpy(lValid).long().cuda()\n",
    "    if (markTest):\n",
    "        xTest = torch.from_numpy(dTest).long().cuda()\n",
    "        yTest = torch.from_numpy(lTest).long().cuda()\n",
    "\n",
    "    # batch size processing.\n",
    "    train = torchdata.TensorDataset(xTrain, yTrain)\n",
    "    trainloader = torchdata.DataLoader(train, batch_size=batchsize, shuffle=False)\n",
    "    valid = torchdata.TensorDataset(xValid, yValid)\n",
    "    validloader = torchdata.DataLoader(valid, batch_size=batchsize, shuffle=False)\n",
    "    if (markTest):\n",
    "        test = torchdata.TensorDataset(xTest, yTest)\n",
    "        testloader = torchdata.DataLoader(test, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "    # get training weights.\n",
    "    lbTrain = [item for sublist in lTrain.tolist() for item in sublist]\n",
    "    weights = []\n",
    "    for lb in range(2):\n",
    "        weights.append(1 - lbTrain.count(lb) / len(lbTrain))\n",
    "    lbWeights = torch.FloatTensor(weights).cuda()\n",
    "\n",
    "    # build the model of recurrent neural network.\n",
    "    preWTwin = torch.from_numpy(preWTwin)\n",
    "    preWMsg = torch.from_numpy(preWMsg)\n",
    "    model = TwinRNN(preWTwin, preWMsg, hidSizTwin=_TRnnHidSiz_, hidSizMsg=_MRnnHidSiz_, hidLayTwin=_TRnnHidLay_, hidLayMsg=_MRnnHidLay_)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print('[INFO] <TwinRNNTrain> ModelType: TwinRNN.')\n",
    "    print('[INFO] <TwinRNNTrain> Code Part: EmbedDim: %d, MaxLen: %d, HidNodes: %d, HidLayers: %d.' % (_TwinEmbedDim_, _TwinMaxLen_, _TRnnHidSiz_, _TRnnHidLay_))\n",
    "    print('[INFO] <TwinRNNTrain> Msg  Part: EmbedDim: %d, MaxLen: %d, HidNodes: %d, HidLayers: %d.' % (_MsgEmbedDim_, _MsgMaxLen_, _MRnnHidSiz_, _MRnnHidLay_))\n",
    "    print('[INFO] <TwinRNNTrain> BatchSize: %d, LearningRate: %.4f, MaxEpoch: %d, PerEpoch: %d, JudEpoch: %d.' % (batchsize, learnRate, _TRnnMaxEpoch_, _TRnnPerEpoch_, _TRnnJudEpoch_))\n",
    "    # optimizing with stochastic gradient descent.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learnRate)\n",
    "    # seting loss function as mean squared error.\n",
    "    criterion = nn.CrossEntropyLoss(weight=lbWeights)\n",
    "    # memory\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "    # run on each epoch.\n",
    "    accList = [0]\n",
    "    for epoch in range(_TRnnMaxEpoch_):\n",
    "        # training phase.\n",
    "        model.train()\n",
    "        lossTrain = 0\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        for iter, (data, label) in enumerate(trainloader):\n",
    "            # data conversion.\n",
    "            data = data.to(device)\n",
    "            label = label.contiguous().view(-1)\n",
    "            label = label.to(device)\n",
    "            # back propagation.\n",
    "            optimizer.zero_grad()  # set the gradients to zero.\n",
    "            yhat = model.forward(data)  # get output\n",
    "            loss = criterion(yhat, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # statistic\n",
    "            lossTrain += loss.item() * len(label)\n",
    "            preds = yhat.max(1)[1]\n",
    "            predictions.extend(preds.int().tolist())\n",
    "            labels.extend(label.int().tolist())\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        lossTrain /= len(dTrain)\n",
    "        # train accuracy.\n",
    "        accTrain = accuracy_score(labels, predictions) * 100\n",
    "\n",
    "        # validation phase.\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        with torch.no_grad():\n",
    "            for iter, (data, label) in enumerate(validloader):\n",
    "                # data conversion.\n",
    "                data = data.to(device)\n",
    "                label = label.contiguous().view(-1)\n",
    "                label = label.to(device)\n",
    "                # forward propagation.\n",
    "                yhat = model.forward(data)  # get output\n",
    "                # statistic\n",
    "                preds = yhat.max(1)[1]\n",
    "                predictions.extend(preds.int().tolist())\n",
    "                labels.extend(label.int().tolist())\n",
    "                torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # valid accuracy.\n",
    "        accValid = accuracy_score(labels, predictions) * 100\n",
    "        accList.append(accValid)\n",
    "\n",
    "        # testing phase.\n",
    "        if (markTest):\n",
    "            model.eval()\n",
    "            predictions = []\n",
    "            labels = []\n",
    "            with torch.no_grad():\n",
    "                for iter, (data, label) in enumerate(testloader):\n",
    "                    # data conversion.\n",
    "                    data = data.to(device)\n",
    "                    label = label.contiguous().view(-1)\n",
    "                    label = label.to(device)\n",
    "                    # forward propagation.\n",
    "                    yhat = model.forward(data)  # get output\n",
    "                    # statistic\n",
    "                    preds = yhat.max(1)[1]\n",
    "                    predictions.extend(preds.int().tolist())\n",
    "                    labels.extend(label.int().tolist())\n",
    "                    torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # test accuracy.\n",
    "            accTest = accuracy_score(labels, predictions) * 100\n",
    "\n",
    "        # output information.\n",
    "        if (0 == (epoch + 1) % _TRnnPerEpoch_):\n",
    "            strAcc = '[Epoch {:03}] loss: {:.3}, train acc: {:.3f}%, valid acc: {:.3f}%.'.format(epoch + 1, lossTrain, accTrain, accValid)\n",
    "            if (markTest):\n",
    "                strAcc = strAcc[:-1] + ', test acc: {:.3f}%.'.format(accTest)\n",
    "            print(strAcc)\n",
    "        # save the best model.\n",
    "        if (accList[-1] > max(accList[0:-1])):\n",
    "            torch.save(model.state_dict(), tempPath + '/model_TwinRNN.pth')\n",
    "        # stop judgement.\n",
    "        if (epoch >= _TRnnJudEpoch_) and (accList[-1] < min(accList[-1-_TRnnJudEpoch_:-1])):\n",
    "            break\n",
    "\n",
    "    # load best model.\n",
    "    model.load_state_dict(torch.load(tempPath + '/model_TwinRNN.pth'))\n",
    "    print('[INFO] <TwinRNNTrain> Finish training TwinRNN model. (Best model: ' + tempPath + '/model_TwinRNN.pth)')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwinRNNTest(model, dTest, lTest, batchsize=64):\n",
    "    '''\n",
    "    Test the TwinRNN model.\n",
    "    :param model: deep learning model.\n",
    "    :param dTest: test data.\n",
    "    :param lTest: test label.\n",
    "    :param batchsize: number of samples in a batch\n",
    "    :return: predictions - predicted labels. [[0], [1], ...]\n",
    "             accuracy - the total test accuracy. numeric\n",
    "    '''\n",
    "\n",
    "    # tensor data processing.\n",
    "    xTest = torch.from_numpy(dTest).long().cuda()\n",
    "    yTest = torch.from_numpy(lTest).long().cuda()\n",
    "\n",
    "    # batch size processing.\n",
    "    test = torchdata.TensorDataset(xTest, yTest)\n",
    "    testloader = torchdata.DataLoader(test, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "    # load the model of recurrent neural network.\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # testing phase.\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for iter, (data, label) in enumerate(testloader):\n",
    "            # data conversion.\n",
    "            data = data.to(device)\n",
    "            label = label.contiguous().view(-1)\n",
    "            label = label.to(device)\n",
    "            # forward propagation.\n",
    "            yhat = model.forward(data)  # get output\n",
    "            # statistic\n",
    "            preds = yhat.max(1)[1]\n",
    "            predictions.extend(preds.int().tolist())\n",
    "            labels.extend(label.int().tolist())\n",
    "            torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # testing accuracy.\n",
    "    accuracy = accuracy_score(labels, predictions) * 100\n",
    "    predictions = [[item] for item in predictions]\n",
    "\n",
    "    return predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1296840549.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    predictions, accuracy = TwinRNNTest(model, dataTest, labelTest, batchsize=_TRnnBatchSz_)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " # TwinRNNTest\n",
    "    predictions, accuracy = TwinRNNTest(model, dataTest, labelTest, batchsize=_TRnnBatchSz_)\n",
    "    _, confusion = OutputEval(predictions, labelTest, 'TwinRNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dvide before after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DivideBeforeAfter(diffProps):\n",
    "    # create temp folder.\n",
    "    if not os.path.exists(tempPath):\n",
    "        os.mkdir(tempPath)\n",
    "    fp = open(tempPath + 'twinlen.csv', 'w')\n",
    "    \n",
    "    twinProps = []\n",
    "    maxLen = 0\n",
    "    # for each sample in diffProps.\n",
    "    for item in diffProps:\n",
    "        # get the tk, tkT, dfT, lb.\n",
    "        tokens = item[0]\n",
    "        tokenTypes = item[1]\n",
    "        diffTypes = item[2]\n",
    "        label = item[3]\n",
    "        numTokens = len(diffTypes)\n",
    "        # reconstruct tkB, tkTB, tkA, tkTA.\n",
    "        tokensB = [tokens[i] for i in range(numTokens) if (diffTypes[i] <= 0)]\n",
    "        tokenTypesB = [tokenTypes[i] for i in range(numTokens) if (diffTypes[i] <= 0)]\n",
    "        tokensA = [tokens[i] for i in range(numTokens) if (diffTypes[i] >= 0)]\n",
    "        tokenTypesA = [tokenTypes[i] for i in range(numTokens) if (diffTypes[i] >= 0)]\n",
    "        # reconstruct new sample.\n",
    "        sample = [tokensB, tokenTypesB, tokensA, tokenTypesA, label]\n",
    "        twinProps.append(sample)\n",
    "        # get max length.\n",
    "        maxLenAB = max(len(tokenTypesB), len(tokenTypesA))\n",
    "        maxLen = maxLenAB if (maxLen < maxLenAB) else maxLen\n",
    "        fp.write(str(len(tokenTypesB)) + '\\n')\n",
    "        fp.write(str(len(tokenTypesA)) + '\\n')\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
